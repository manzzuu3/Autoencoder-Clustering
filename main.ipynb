{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82a76d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "import random\n",
    "from sklearn.metrics import silhouette_score, pairwise_distances\n",
    "from validclust import dunn\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "908e4d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image_array):\n",
    "    # converting colored images to gray scale\n",
    "    gray = cv2.cvtColor(image_array, cv2.COLOR_BGR2GRAY)\n",
    "    # Reshaping array to a single row with 1024 columns\n",
    "    gray_reshaped = gray.reshape(1, 1024)\n",
    "    # Scaling the features to values between zero and 1\n",
    "    scaled = gray_reshaped / (255)\n",
    "    return gray_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c85dc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_encoder(image_array):\n",
    "    # converting colored images to gray scale\n",
    "    gray = cv2.cvtColor(image_array, cv2.COLOR_BGR2GRAY)\n",
    "    gray = gray/(255)\n",
    "    return gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58f2b0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(inp_point, cluster_centroids):\n",
    "    # calculating euclidean distance between the data point and cluster centroid.\n",
    "    distances = [np.linalg.norm(inp_point - ctr) for ctr in cluster_centroids]\n",
    "\n",
    "    cluster_no = distances.index(min(distances))\n",
    "\n",
    "    return cluster_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea0b603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recentre_centroids(cluster, data):\n",
    "    # Taking the cluster number and data points as input\n",
    "    # grouping together the data points with same cluster number\n",
    "    unique_clusters = list(set(cluster))\n",
    "    clustered_data_dict = {}\n",
    "    # for all the unique clusters getting the data points belonging to that clusters\n",
    "    for unq_num in unique_clusters: \n",
    "        same_cluster = []\n",
    "        for num, point in zip(cluster, data):\n",
    "            if unq_num == num:\n",
    "                same_cluster.append(point)\n",
    "        clustered_data_dict[unq_num] = np.array(same_cluster)\n",
    "    # updating centroids as mean values of data points present in that cluster\n",
    "    new_centroids = [ np.mean(value, axis = 0) for key, value in clustered_data_dict.items() ]\n",
    "    return new_centroids, clustered_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c200ce0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(data, k, patience):\n",
    "    # chossing k number of centroids randomly.\n",
    "    cluster_centroids = []\n",
    "    terminate = False\n",
    "    patience_count = 0\n",
    "    cluster_old = []\n",
    "    random.seed(99)\n",
    "    for i in range(k):\n",
    "        cluster_centroids.append(random.choice(data))\n",
    "    # calculating distances and assigning clusters\n",
    "    iter_no = 1\n",
    "    # The stop condition is if the cluster formed are same \n",
    "    # for patience number of times\n",
    "    while terminate == False and patience_count < patience:\n",
    "        if iter_no != 1:\n",
    "            cluster_centroids, clustered_data_dict = recentre_centroids(cluster, data)\n",
    "        cluster = [ calculate_distance(point, cluster_centroids) for point in data ]\n",
    "        if cluster == cluster_old:\n",
    "            patience_count += 1\n",
    "#             print(\"patience reached\", patience_count)\n",
    "            if patience_count >= patience:\n",
    "                terminate = True\n",
    "        else:\n",
    "            patience_count = 0\n",
    "            terminate = False\n",
    "        cluster_old = cluster\n",
    "        iter_no += 1\n",
    "#         print(\" no of iterations : \", iter_no)\n",
    "    return cluster, iter_no, clustered_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc9f5ad",
   "metadata": {},
   "source": [
    "###  loading cifar10 data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d302575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1ca9bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train  (50000, 32, 32, 3)\n",
      "shape of test (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of train \", X_train.shape)\n",
    "print(\"shape of test\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3058db",
   "metadata": {},
   "source": [
    "### Part 1Using only test data for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd236a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " shape of processed data :  (10000, 1024)\n"
     ]
    }
   ],
   "source": [
    "processed_X_test = np.array([ preprocess(img_array) for img_array in X_test ])\n",
    "processed_X_test = processed_X_test.reshape(10000, 1024)\n",
    "print(\" shape of processed data : \", processed_X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4ec4d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▍                                       | 1/10 [00:04<00:37,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.17953866855626427\n",
      "dunns index is  0.0919845985373622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████▊                                   | 2/10 [00:08<00:32,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 3 The average silhouette_score is : 0.11590471626887923\n",
      "dunns index is  0.09005725342476706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|█████████████▏                              | 3/10 [00:14<00:35,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 4 The average silhouette_score is : 0.10320309347694681\n",
      "dunns index is  0.08368556326723489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████▌                          | 4/10 [00:23<00:38,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 5 The average silhouette_score is : 0.08747868928225702\n",
      "dunns index is  0.08249664087520184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████                      | 5/10 [00:37<00:46,  9.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 6 The average silhouette_score is : 0.07902653793812217\n",
      "dunns index is  0.09142460937653932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████▍                 | 6/10 [00:48<00:38,  9.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 7 The average silhouette_score is : 0.07561892205073495\n",
      "dunns index is  0.08310120111043925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████▊             | 7/10 [01:05<00:36, 12.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 8 The average silhouette_score is : 0.06647005100891981\n",
      "dunns index is  0.09773129466140822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████▏        | 8/10 [01:39<00:38, 19.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 9 The average silhouette_score is : 0.06468473843763464\n",
      "dunns index is  0.08665430985693591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|███████████████████████████████████████▌    | 9/10 [02:19<00:25, 25.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 10 The average silhouette_score is : 0.05402163199264537\n",
      "dunns index is  0.08993630211024856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [02:52<00:00, 17.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 11 The average silhouette_score is : 0.054782964733661274\n",
      "dunns index is  0.09143259681851422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "dist = pairwise_distances(processed_X_test)\n",
    "res = []\n",
    "for n_clust in tqdm.tqdm(range(2, 12)):\n",
    "    k = n_clust\n",
    "    clusters_nos, iter_no, clustered_data_dict = clustering(processed_X_test, k, patience = 5)\n",
    "    silhouette_avg = silhouette_score(processed_X_test, clusters_nos)\n",
    "    dunn_index = dunn(dist, np.array(clusters_nos))\n",
    "    print(\"For n_clusters =\", k,\"The average silhouette_score is :\", silhouette_avg)\n",
    "    print(\"dunns index is \", dunn_index)\n",
    "    res.append([k, silhouette_avg, dunn_index] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dd0f27",
   "metadata": {},
   "source": [
    "### For 10 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0211fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 10 The average silhouette_score is : 0.05402163199264537\n",
      "dunns index is  0.08993630211024856\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "clusters_nos, iter_no, clustered_data_dict = clustering(processed_X_test, k, patience = 5)\n",
    "silhouette_avg = silhouette_score(processed_X_test, clusters_nos)\n",
    "dunn_index = dunn(dist, np.array(clusters_nos))\n",
    "print(\"For n_clusters =\", k,\"The average silhouette_score is :\", silhouette_avg)\n",
    "print(\"dunns index is \", dunn_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7114cc7",
   "metadata": {},
   "source": [
    "## Part2 - Auto encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b266fb9",
   "metadata": {},
   "source": [
    "###### We are supposed to use training data from cifar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcc765ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, Dense, Flatten, MaxPooling2D, Dropout, Input, UpSampling2D\n",
    "from keras import initializers, Sequential\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a740e6",
   "metadata": {},
   "source": [
    "### Pre processing cifar train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa693ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " shape of processed data :  (50000, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "processed_X_train = np.array([ preprocess_encoder(img_array) for img_array in X_train ])\n",
    "print(\" shape of processed data : \", processed_X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0b6c35",
   "metadata": {},
   "source": [
    "### Defining an encoder model\n",
    "The encoder part takes the input images and pass them through series of convolution and max pooling layers to produce the image in lower dimension with important features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eaa637ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-14 16:03:45.653517: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-11-14 16:03:45.653897: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "input_dimension = (processed_X_train.shape[1], processed_X_train.shape[2], 1)\n",
    "inp_layer = Input(shape=(input_dimension))\n",
    "encoder = Conv2D(filters = 3, kernel_size = (3, 3), padding = 'same',strides = (1,1), activation = 'relu',  kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
    "                 bias_initializer=initializers.Zeros, activity_regularizer=regularizers.l1(10e-9) )(inp_layer)\n",
    "encoder = MaxPooling2D(pool_size = (2,2), padding = 'same')(encoder)\n",
    "encoder = Conv2D(filters = 1, kernel_size = (3, 3), padding = 'same',strides = (1,1), activation = 'relu',  kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
    "                 bias_initializer=initializers.Zeros, activity_regularizer=regularizers.l1(10e-9))(encoder)\n",
    "middle_layer = MaxPooling2D(pool_size = (2,2), padding = 'same')(encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c476753d",
   "metadata": {},
   "source": [
    "### Defining a decoder\n",
    "Decoder accepts the ouput from encoders final layer, then the layers are stacked in reverse order as of encoder, to reconstruct the input. The final layer has a the dimension equal to the input_dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8da1ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Conv2D(filters = 1, kernel_size = (3, 3), padding = 'same',strides = (1,1), activation = 'relu',  kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
    "                 bias_initializer=initializers.Zeros, activity_regularizer=regularizers.l1(10e-9))(middle_layer)\n",
    "decoder = UpSampling2D((2,2))(decoder)\n",
    "decoder = Conv2D(filters = 3, kernel_size = (3, 3), padding = 'same',strides = (1,1), activation = 'relu',  kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
    "                 bias_initializer=initializers.Zeros, activity_regularizer=regularizers.l1(10e-9) )(decoder)\n",
    "decoder = UpSampling2D((2,2))(decoder)\n",
    "output_layer =  Conv2D(filters = 1, kernel_size = (3, 3), padding = 'same',strides = (1,1), activation = 'relu',  kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
    "                 bias_initializer=initializers.Zeros, activity_regularizer=regularizers.l1(10e-9) )(decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1789fe5",
   "metadata": {},
   "source": [
    "### Defining Auto encoder\n",
    "Here the input layer and the decoder output are stacked together, to train the weights of both encoder and decoder such that the weights encode the image in smaller dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19600b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=inp_layer, outputs=output_layer)\n",
    "# compile autoencoder model\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "013275d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 3)         30        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 1)         28        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 1)           10        \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 16, 16, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 3)         30        \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 1)         28        \n",
      "=================================================================\n",
      "Total params: 126\n",
      "Trainable params: 126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85a252cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-14 16:04:43.173816: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-14 16:04:43.177377: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2021-11-14 16:04:43.353798: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 - 16s - loss: 0.0298\n",
      "Epoch 2/10\n",
      "1563/1563 - 16s - loss: 0.0144\n",
      "Epoch 3/10\n",
      "1563/1563 - 16s - loss: 0.0141\n",
      "Epoch 4/10\n",
      "1563/1563 - 16s - loss: 0.0138\n",
      "Epoch 5/10\n",
      "1563/1563 - 16s - loss: 0.0134\n",
      "Epoch 6/10\n",
      "1563/1563 - 16s - loss: 0.0133\n",
      "Epoch 7/10\n",
      "1563/1563 - 16s - loss: 0.0133\n",
      "Epoch 8/10\n",
      "1563/1563 - 16s - loss: 0.0133\n",
      "Epoch 9/10\n",
      "1563/1563 - 16s - loss: 0.0133\n",
      "Epoch 10/10\n",
      "1563/1563 - 16s - loss: 0.0133\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(processed_X_train, processed_X_train, epochs=10, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e79fb57",
   "metadata": {},
   "source": [
    "### Using encoder to predict on train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f8f84d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(inputs=inp_layer, outputs=middle_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55abcd9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-14 16:08:38.255045: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "encoder_features = encoder.predict(processed_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a98b3c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(processed_X_train[111])\n",
    "plt.show()\n",
    "plt.imshow(encoder_features[111])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48322843",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_encoded = encoder_features.reshape(50000, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2f9c75",
   "metadata": {},
   "source": [
    "### Running clustering on encoded features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07db446a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 10 The average silhouette_score is : 0.10401671\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "clusters_nos, iter_no, clustered_data_dict = clustering(flat_encoded, k, patience = 5)\n",
    "silhouette_avg = silhouette_score(flat_encoded, clusters_nos)\n",
    "print(\"For n_clusters =\", k,\"The average silhouette_score is :\", silhouette_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25d54b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dunns index is  0.020386063\n"
     ]
    }
   ],
   "source": [
    "dist = pairwise_distances(flat_encoded)\n",
    "dunn_index = dunn(dist, np.array(clusters_nos))\n",
    "print(\"dunns index is \", dunn_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_base",
   "language": "python",
   "name": "tf_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
